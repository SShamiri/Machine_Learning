{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c4b0fd1-741f-44dd-b1db-e3f3b1e69b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Automated MLflow tracking in MLlib:**\n",
    "\n",
    "- MLflow provides automated tracking for model tuning with MLlib\n",
    "- With automated MLflow tracking, when you run tuning code using `CrossValidator` or `TrainValidationSplit`, the specified hyperparameters and evaluation metrics are automatically logged in MLflow\n",
    "- It makes easy to identify the optimal model, without automated MLflow tracking you must make explicit API calls to log to MLflow\n",
    "\n",
    "**In this notebook we will learn:** Automated MLflow tracking with MLlib. \n",
    "\n",
    "- In this notebook we will use the PySpark classes `DecisionTreeClassifier` and `CrossValidator` to train and tune a model. MLflow automatically tracks the learning process and saves the results of each run, So you can examine the hyperparameters to understand the impact of each one on the model's performance and find the optimal settings\n",
    "\n",
    "**Dataset:** MNIST handwritten digit recognition dataset, which is included with Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40a2815b-6eba-4df6-a036-28b8d372a13d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 1: Train model without cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78d0749b-9713-42ce-87c4-801ac25bd2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the training and test datasets\n",
    "- **MNIST handwritten digit recognition dataset:** A classic dataset of handwritten digits that is commonly used for training and benchmarking ML algorithms\n",
    "- It consists of 60,000 training images and 10,000 test images, each of which is a 28x28 pixel grayscale image of a handwritten digit\n",
    "- The digits in the dataset are labeled from 0 to 9, and the task is to classify a given image as one of these 10 classes\n",
    " - It is stored in the popular LibSVM dataset format, we will load MNIST dataset using MLlib's LibSVM dataset reader utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "800336e6-eee1-4cff-a3c9-9e8fc23f0fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt\")\n",
    "test = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt\")\n",
    "\n",
    "# Cache data for multiple uses\n",
    "training.cache()\n",
    "test.cache()\n",
    "\n",
    "print(\"There are {} training images and {} test images.\".format(training.count(), test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b37e9c5-0e1c-455e-854c-e0ffa5ec7300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09df13e6-4be6-44b2-96a8-a612c8d40c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import the required classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17515eed-b78f-4a2f-b965-d1c45e31edd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3655b552-7e31-4407-a887-003fe6141865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65037e1-1716-4f4e-b860-e0b79b3b9b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# StringIndexer: Convert the input column \"label\" (digits) to categorical values\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "# DecisionTreeClassifier: Learn to predict column \"indexedLabel\" using the \"features\" column\n",
    "dtc = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", maxBins=8, maxDepth=4)\n",
    "# Chain indexer + dtc together into a single ML Pipeline\n",
    "pipeline = Pipeline(stages=[indexer, dtc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0378714a-a215-49d5-b05c-ac287718fbb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5d1d06-b2a8-4f72-abf3-4e2ccae0adfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline on the training dataset\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00a3851c-e5ed-4d24-97a7-7434f2c95e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create an evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0cdf88e-b512-493a-a76a-2af7a972e00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an evaluator using \"weightedPrecision\".\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", metricName=\"weightedPrecision\")\n",
    "test_metric = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae56672f-013c-4894-81be-e56b9a2e0a43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the metric and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1ff572-2362-4f06-9470-c616640ba649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the model and evaluation metric in MLflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.spark.log_model(spark_model=model, artifact_path='best-model')\n",
    "  mlflow.log_metric('test_' + evaluator.getMetricName(), test_metric)\n",
    "  \n",
    "  # Log all the parameters in MLflow\n",
    "  params = dtc.extractParamMap()\n",
    "  for param_name, param_value in params.items():\n",
    "    mlflow.log_param(param_name.name, param_value)\n",
    "    print(f\"{param_name.name}: {param_value}\")\n",
    "\n",
    "# Print the evaluation metric\n",
    "print(\"Test Weighted Precision:\", test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94dd1850-6663-4040-8308-917ed8ce95c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the maxDepth and maxBins parameters from the fitted DecisionTreeClassifier\n",
    "max_depth = model.stages[-1].getMaxDepth()\n",
    "max_bins = model.stages[-1].getMaxBins()\n",
    "\n",
    "# Print the values of maxDepth and maxBins\n",
    "print(\"maxDepth:\", max_depth)\n",
    "print(\"maxBins:\", max_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99695ddc-0994-48b6-bdc3-84000147220d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 2: Train model with cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd312f5-f501-46e5-98fc-b4874384802a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4812a91-acd1-4241-b19d-b0e3e9328c2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt\")\n",
    "test = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt\")\n",
    "\n",
    "# Cache data for multiple uses\n",
    "training.cache()\n",
    "test.cache()\n",
    "\n",
    "print(\"There are {} training images and {} test images.\".format(training.count(), test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65bb8794-4871-4700-8a8e-770404b8f999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import the required classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40dd2c7-3df5-4675-bc32-66c487ce04a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db44e858-40cf-402c-af34-bf51e8b03dea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the ML pipeline \n",
    "\n",
    "In this example, we have to do some preprocessing of the data before we can use the data to train a model. MLlib provides **pipelines** that allows us to combine multiple steps into a single workflow\n",
    "\n",
    "In this example, we will build a two-step pipeline:\n",
    "1. `StringIndexer` converts the labels from numeric values to categorical values. \n",
    "2. `DecisionTreeClassifier` trains a decision tree that can predict the \"label\" column based on the data in the \"features\" column.\n",
    "\n",
    "For more information:  \n",
    "[Pipelines](http://spark.apache.org/docs/latest/ml-pipeline.html#ml-pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4555ad0a-26c4-4242-9cd4-9361480824f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# StringIndexer: Convert the input column \"label\" (digits) to categorical values\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "# DecisionTreeClassifier: Learn to predict column \"indexedLabel\" using the \"features\" column\n",
    "dtc = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", maxBins=8, maxDepth=4)\n",
    "# Chain indexer + dtc together into a single ML Pipeline\n",
    "pipeline = Pipeline(stages=[indexer, dtc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6198f565-8426-4b15-a019-d0915bd4fc94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run the cross-validation \n",
    "\n",
    "We have defined the pipeline, now we can run the cross validation to tune the model's hyperparameters. During this process, MLflow automatically tracks the models produced by `CrossValidator`, along with their evaluation metrics. This allows you to investigate how specific hyperparameters affect the model's performance.\n",
    "\n",
    "In this example, we will examine two hyperparameters in the cross-validation:\n",
    "\n",
    "* `maxDepth`. This parameter determines how deep, and thus how large, the tree can grow. \n",
    "* `maxBins`. For efficient distributed training of Decision Trees, MLlib discretizes (or \"bins\") continuous features into a finite number of values. The number of bins is controlled by `maxBins`. In this example, the number of bins corresponds to the number of grayscale levels; `maxBins=2` turns the images into black and white images.\n",
    "\n",
    "For more information:  \n",
    "[maxBins](https://spark.apache.org/docs/latest/mllib-decision-tree.html#split-candidates)  \n",
    "[maxDepth](https://spark.apache.org/docs/latest/mllib-decision-tree.html#stopping-rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfd4793b-297f-4477-b22e-defb572e3a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create an evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c578e216-0f8e-4001-aa50-a6a14d9002eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an evaluator using \"weightedPrecision\".\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", metricName=\"weightedPrecision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50db1265-dcce-45a2-86d6-f5cee5f172fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import CrossValidator, ParamGridBuilder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1f31bb-6707-41f6-a593-0d16dc01466a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50704ee1-d5fd-4afa-bc13-a8197cae8f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define the parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49592550-2ca4-431c-85ae-a5d35fa33cb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid to examine\n",
    "grid = ParamGridBuilder() \\\n",
    "  .addGrid(dtc.maxDepth, [2, 3, 4, 5, 6, 7, 8]) \\\n",
    "  .addGrid(dtc.maxBins, [2, 4, 8]) \\\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bdc580d-1a77-4449-b762-cd7c6f43fe81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e003c164-242e-407f-9bb6-48f8aec4bc07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=pipeline, evaluator=evaluator, estimatorParamMaps=grid, numFolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9428d52b-a35a-4610-a51b-223c64282852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8861467-74c3-40ac-a2fd-4746ded0682e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run `CrossValidator`.  If an MLflow tracking server is available, `CrossValidator` automatically logs each run to MLflow, along with the evaluation metric calculated on the held-out data, under the current active run. If no run is active, a new one is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6acfbfd3-a524-4d22-b4b6-c9175bc90b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explicitly creating a new run, it will allows this cell to be run multiple times\n",
    "# If you omit mlflow.start_run(), then this cell could run once, but a second run would hit conflicts when attempting to overwrite the first run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "with mlflow.start_run():\n",
    "  # Run the cross validation on the training dataset. The cv.fit() call returns the best model it found.\n",
    "  cvModel = cv.fit(training)\n",
    "\n",
    "  # Retrieve the best model's parameters\n",
    "  bestParams = cvModel.bestModel.stages[-1].extractParamMap()\n",
    "\n",
    "  # Evaluate the best model's performance on the test dataset and log the result.\n",
    "  test_metric = evaluator.evaluate(cvModel.transform(test))\n",
    "  mlflow.log_metric('test_' + evaluator.getMetricName(), test_metric)\n",
    "\n",
    "  # Log the best model.\n",
    "  mlflow.spark.log_model(spark_model=cvModel.bestModel, artifact_path='best-model')\n",
    "\n",
    "  # Log all the parameters in MLflow\n",
    "  params = dtc.extractParamMap()\n",
    "  for param_name, param_value in params.items():\n",
    "    mlflow.log_param(param_name.name, param_value)\n",
    "    print(f\"{param_name.name}: {param_value}\")\n",
    "\n",
    "  # Print the evaluation metric\n",
    "  print(\"Test Weighted Precision:\", test_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a238ec3-de39-4abf-adc0-860d7bd6a2b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- maxDepth: 4\n",
    "- maxBins: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ca9a193-75d8-4e0f-ad7f-2ae007c10a09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  # Print the best parameters\n",
    "  print(\"Best parameters: \")\n",
    "  print(\"maxDepth =\", bestParams[dtc.maxDepth])\n",
    "  print(\"maxBins =\", bestParams[dtc.maxBins])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3_1_Automated MLflow Tracking and Cross-Validation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
