{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7879e293-9ed4-41b3-a716-70732681e4ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Databricks Runtime for Machine Learning includes,\n",
    "1) [Hyperopt](https://github.com/hyperopt/hyperopt): A library for ML hyperparameter tuning in Python\n",
    "2) [Apache Spark MLlib](https://spark.apache.org/docs/latest/ml-guide.html): A library of distributed algorithms for training ML models (also called as \"Spark ML\")\n",
    "\n",
    "**In this notebook we will learn to use them together:** We have distributed ML workloads in Python for which we want to tune hyperparameters\n",
    "\n",
    "This notebook includes two sections:\n",
    "* **Part 1: Run distributed training using MLlib:** In this section we will do the MLlib model training without hyperparameter tuning\n",
    "* **Part 2: Use Hyperopt to tune hyperparameters in the distributed training workflow:** Here we will wrap the MLlib code with Hyperopt for tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eae9173-2e33-4357-bc34-276637ad640b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 1: Run distributed training using MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec72dc0e-737d-4839-bd95-94c2bbafeb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load data\n",
    "- **MNIST handwritten digit recognition dataset:** A classic dataset of handwritten digits that is commonly used for training and benchmarking ML algorithms\n",
    "- It consists of 60,000 training images and 10,000 test images, each of which is a 28x28 pixel grayscale image of a handwritten digit\n",
    "- The digits in the dataset are labeled from 0 to 9, and the task is to classify a given image as one of these 10 classes\n",
    " - It is stored in the popular LibSVM dataset format, we will load MNIST dataset using MLlib's LibSVM dataset reader utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d7c02bf-4584-4fb2-aa74-997064612490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_training_data = spark.read.format(\"libsvm\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt\")\n",
    "test_data = spark.read.format(\"libsvm\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt\")\n",
    "\n",
    "# Cache data for multiple uses\n",
    "full_training_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "print(f\"There are {full_training_data.count()} training images and {test_data.count()} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "798f3c32-d463-4bb0-9186-a1775bfe6f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Randomly split full_training data for tuning\n",
    "training_data, validation_data = full_training_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e384ff68-3edb-40e7-84a5-72ee284cd416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add3be15-48bc-4b8b-8e62-46512917642f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea3a8fb-1e82-414d-8333-fe4794a6a8cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "753b1328-4dd2-4664-9940-d7dabf44ea1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a function to train a model\n",
    "\n",
    "We will define a function to train a decision tree. Wrapping the training code in a function is important for passing the function to Hyperopt for tuning later.\n",
    "\n",
    "**Details:** The tree algorithm needs to know that the labels are categories 0-9, rather than continuous values. This example uses the `StringIndexer` class to do this.  A `Pipeline` ties this feature preprocessing together with the tree algorithm.  ML Pipelines are tools Spark provides for piecing together Machine Learning algorithms into workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d2d347-f049-4618-83b9-d67b5765d685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d496c39-059a-417e-99ac-9b9a4e36b1d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MLflow autologging for `pyspark.ml` requires MLflow version 1.17.0 or above.\n",
    "# This try-except logic allows the notebook to run with older versions of MLflow.\n",
    "try:\n",
    "  import mlflow.pyspark.ml\n",
    "  mlflow.pyspark.ml.autolog()\n",
    "except:\n",
    "  print(f\"Your version of MLflow ({mlflow.__version__}) does not support pyspark.ml for autologging. To use autologging, upgrade your MLflow client version or use Databricks Runtime for ML 8.3 or above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181ae727-ecd1-4cc7-9acd-655b9cb60600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_tree(minInstancesPerNode, maxBins):\n",
    "  '''\n",
    "  This train() function:\n",
    "   - takes hyperparameters as inputs (for tuning later)\n",
    "   - returns the F1 score on the validation dataset\n",
    "\n",
    "  Wrapping code as a function makes it easier to reuse the code later with Hyperopt.\n",
    "  '''\n",
    "  # Use MLflow to track training.\n",
    "  # Specify \"nested=True\" since this single model will be logged as a child run of Hyperopt's run.\n",
    "  with mlflow.start_run(nested=True):\n",
    "    \n",
    "    # StringIndexer: Read input column \"label\" (digits) and annotate them as categorical values.\n",
    "    indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "    \n",
    "    # DecisionTreeClassifier: Learn to predict column \"indexedLabel\" using the \"features\" column.\n",
    "    dtc = DecisionTreeClassifier(labelCol=\"indexedLabel\",\n",
    "                                 minInstancesPerNode=minInstancesPerNode,\n",
    "                                 maxBins=maxBins)\n",
    "    \n",
    "    # Chain indexer and dtc together into a single ML Pipeline.\n",
    "    pipeline = Pipeline(stages=[indexer, dtc])\n",
    "    model = pipeline.fit(training_data)\n",
    "\n",
    "    # Define an evaluation metric and evaluate the model on the validation dataset.\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", metricName=\"f1\")\n",
    "    predictions = model.transform(validation_data)\n",
    "    validation_metric = evaluator.evaluate(predictions)\n",
    "    mlflow.log_metric(\"val_f1_score\", validation_metric)\n",
    "\n",
    "  return model, validation_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45800614-3ba7-46f2-8dff-7364889c57d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4b9633-26d9-4af4-ae85-667e22cad5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "initial_model, val_metric = train_tree(minInstancesPerNode=200, maxBins=2)\n",
    "print(f\"The trained decision tree achieved an F1 score of {val_metric} on the validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c644118-8dc4-40f8-b50c-03f46928b0e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7f782bc-42d7-4359-908c-45d32e5fd0c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Part 2: Use Hyperopt to tune hyperparameters\n",
    "\n",
    "In this section, you create the Hyperopt workflow. \n",
    "* Define a function to minimize\n",
    "* Define a search space over hyperparameters\n",
    "* Specify the search algorithm and use `fmin()` to tune the model\n",
    "\n",
    "For more information about the Hyperopt APIs, see the [Hyperopt documentation](http://hyperopt.github.io/hyperopt/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d0f905d-0435-4a47-8e3c-d6a30a3d406d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define a function to minimize\n",
    "\n",
    "* Input: hyperparameters\n",
    "* Internally: Reuse the training function defined above.\n",
    "* Output: loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3418abfc-c126-4384-a3e3-f3b046690003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "def train_with_hyperopt(params):\n",
    "  \"\"\"\n",
    "  An example train method that calls into MLlib.\n",
    "  This method is passed to hyperopt.fmin().\n",
    "  \n",
    "  :param params: hyperparameters as a dict. Its structure is consistent with how search space is defined. See below.\n",
    "  :return: dict with fields 'loss' (scalar loss) and 'status' (success/failure status of run)\n",
    "  \"\"\"\n",
    "  # For integer parameters, make sure to convert them to int type if Hyperopt is searching over a continuous range of values.\n",
    "  minInstancesPerNode = int(params['minInstancesPerNode'])\n",
    "  maxBins = int(params['maxBins'])\n",
    "\n",
    "  model, f1_score = train_tree(minInstancesPerNode, maxBins)\n",
    "  \n",
    "  # Hyperopt expects you to return a loss (for which lower is better), so take the negative of the f1_score (for which higher is better).\n",
    "  loss = - f1_score\n",
    "  return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b322e1fa-d8c6-491a-b225-837ef64544d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the search space over hyperparameters\n",
    "\n",
    "This example tunes two hyperparameters: `minInstancesPerNode` and `maxBins`. See the [Hyperopt documentation](https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions) for details on defining a search space and parameter expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08dc186e-5b7d-4235-b25d-8a4a072dfaa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "space = {\n",
    "  'minInstancesPerNode': hp.uniform('minInstancesPerNode', 10, 200),\n",
    "  'maxBins': hp.uniform('maxBins', 2, 32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a0e05b3-7f07-4154-a540-96e266c444d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Select the search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "055b6c8e-6c52-4530-8590-8681fdc3db0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- You must also specify which search algorithm to use. The two main choices are:\n",
    "  - `hyperopt.tpe.suggest`: Tree of Parzen Estimators, a Bayesian approach which iteratively and adaptively selects new hyperparameter settings to explore based on previous results\n",
    "  - `hyperopt.rand.suggest`: Random search, a non-adaptive approach that randomly samples the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f81474-5931-4193-ac5e-877e2a1c328c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "algo = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72cab5cf-e0ee-438c-8e52-edcbebf15d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run the tuning algorithm with Hyperopt fmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8bc18b2-1936-4227-8bfa-a5c66cd2f712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Important:**  \n",
    "When using Hyperopt with MLlib and other distributed training algorithms, do not pass a `trials` argument to `fmin()`. When you do not include the `trials` argument, Hyperopt uses the default `Trials` class, which runs on the cluster driver. Hyperopt needs to evaluate each trial on the driver node so that each trial can initiate distributed training jobs.  \n",
    "\n",
    "Do not use the `SparkTrials` class with MLlib. `SparkTrials` is designed to distribute trials for algorithms that are not themselves distributed. MLlib uses distributed computing already and is not compatible with `SparkTrials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c27b3844-7f09-4064-8859-3245d50686d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "  best_params = fmin(\n",
    "    fn=train_with_hyperopt,\n",
    "    space=space,\n",
    "    algo=algo,\n",
    "    max_evals=8\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28bac71d-5073-425e-96ee-c2be31b530a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Best hyperparametrs\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfeadf58-f32a-436d-b808-5068b9970ab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Retrain the model on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18affbe4-1b95-4bb8-835b-f4212f4735c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_minInstancesPerNode = int(best_params['minInstancesPerNode'])\n",
    "best_maxBins = int(best_params['maxBins'])\n",
    "\n",
    "final_model, val_f1_score = train_tree(best_minInstancesPerNode, best_maxBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068e6c89-595f-48ed-9293-d2127c189fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The retrained decision tree achieved an F1 score of {val_f1_score} on the validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be379a9e-c968-41ed-90dc-28f3c135c24a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Use test dataset to compare evaluation metrics for the initial and \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "473b3eae-dbbb-445c-8353-52234960ea1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", metricName=\"f1\")\n",
    "\n",
    "initial_model_test_metric = evaluator.evaluate(initial_model.transform(test_data))\n",
    "final_model_test_metric = evaluator.evaluate(final_model.transform(test_data))\n",
    "\n",
    "print(f\"On the test data, the initial (untuned) model achieved F1 score {initial_model_test_metric}, and the final (tuned) model achieved {final_model_test_metric}.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3_4_Tuning distributed training algorithms with Hyperopt & Apache Spark MLlib",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
